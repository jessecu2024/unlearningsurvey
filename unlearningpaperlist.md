* **Y. Cao and J. Yang**, *“Towards making systems forget with machine unlearning,” in Proceedings - IEEE Symposium on Security and Privacy, 2015, vol. 2015-July, pp. 463–480, doi: 10.1109/SP.2015.35.*
* **B. Mirzasoleiman**, *A. Karbasi, and A. Krause, “Deletion-robust submodular maximization: Data summarization with ‘the right to be forgotten,’” in 34th International Conference on Machine Learning, ICML 2017, 2017, vol. 5, pp. 3780–3790.*
* **A. A. Ginart**, *M. Y. Guan, G. Valiant, and J. Zou, “Making AI forget you: Data deletion in machine learning,” in Advances in Neural Information Processing Systems, 2019, vol. 32, no. NeurIPS, pp. 1–14.*
* **M. Jagielski**, *J. Ullman, and A. Oprea, “Auditing differentially private machine learning: How private is private SGD?,” Advances in Neural Information Processing Systems, vol. 2020-Decem, no. NeurIPS, pp. 1–12, 2020.*
* **Y. Wu**, *E. Dobriban, and S. B. Davidson, “DeltaGrad: Rapid retraining of machine learning models,” in 37th International Conference on Machine Learning, ICML 2020, 2020, vol. PartF16814, pp. 10286–10297.*
* **A. Golatkar**, *A. Achille, and S. Soatto, “Forgetting Outside the Box: Scrubbing Deep Networks of Information Accessible from Input-Output Observations,” in European Conference on Computer Vision, 2020, vol. 12374 LNCS, pp. 383–398, doi: 10.1007/978-3-030-58526-6_23.*
* **C. Guo**, *T. Goldstein, A. Hannun, and L. van der Maaten, “Certified data removal from machine learning models,” in 37th International Conference on Machine Learning, ICML 2020, 2020, vol. PartF16814, no. i, pp. 3790–3800.*
* **A. Golatkar**, *A. Achille, and S. Soatto, “Eternal sunshine of the spotless net: Selective forgetting in deep networks,” in Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2020, pp. 9301–9309, doi: 10.1109/CVPR42600.2020.00932.*
* **S. Badillo et al.**, *“An Introduction to Machine UnLearning,” 2020. .*
* **Q. P. Nguyen**, *B. K. Hsiang Low, and P. Jaillet, “Variational Bayesian unlearning,” in Advances in Neural Information Processing Systems, 2020, vol. 2020-Decem, no. NeurIPS, pp. 1–12.*
* **J. Brophy and D. Lowd**, *“Machine Unlearning for Random Forests,” in International Conference on Machine Learning, Sep. 2020, pp. 1092--1104.*
* **T. Shibata**, *G. Irie, D. Ikami, and Y. Mitsuzumi, “Learning with Selective Forgetting,” in IJCAI International Joint Conference on Artificial Intelligence, 2021, pp. 989–996, doi: 10.24963/ijcai.2021/137.*
* **A. Golatkar**, *A. Achille, A. Ravichandran, M. Polito, and S. Soatto, “Mixed-Privacy Forgetting in Deep Networks,” in Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2021, pp. 792–801, doi: 10.1109/CVPR46437.2021.00085.*
* **S. Schelter**, *S. Grafberger, and T. Dunning, “HedgeCut: Maintaining Randomised Trees for Low-Latency Machine Unlearning,” in Proceedings of the ACM SIGMOD International Conference on Management of Data, 2021, pp. 1545–1557, doi: 10.1145/3448016.3457239.*
* **L. Graves**, *V. Nagisetty, and V. Ganesh, “Amnesiac Machine Learning,” in 35th AAAI Conference on Artificial Intelligence, AAAI 2021, 2021, vol. 13A, pp. 11516–11524, doi: 10.1609/aaai.v35i13.17371.*
* **M. Chen**, *Z. Zhang, T. Wang, M. Backes, M. Humbert, and Y. Zhang, “When Machine Unlearning Jeopardizes Privacy,” in Proceedings of the ACM Conference on Computer and Communications Security, 2021, pp. 896–911, doi: 10.1145/3460120.3484756.*
* **L. Bourtoule et al.**, *“Machine Unlearning,” in 2021 IEEE Symposium on Security and Privacy (SP), May 2021, vol. 2021-May, pp. 141–159, doi: 10.1109/SP40001.2021.00019.*
* **V. Gupta**, *C. Jung, S. Neel, A. Roth, S. Sharifi-Malvajerdi, and C. Waites, “Adaptive Machine Unlearning,” in Advances in Neural Information Processing Systems, 2021, vol. 20, no. NeurIPS, pp. 16319–16330.*
* **A. Sekhari**, *J. Acharya, G. Kamath, and A. T. Suresh, “Remember What YouWant to Forget: Algorithms for Machine Unlearning,” in Advances in Neural Information Processing Systems, 2021, vol. 22, no. NeurIPS, pp. 18075–18086.*
* **C. Pan and E. Chien**, *“Unlearning Graph Classifiers with Limited Data Resources,” in WWW, 2022, pp. 716–726, doi: 10.1145/3543507.3583547.*
* **Y. Jiang**, *S. Liu, T. Zhao, W. Li, and X. Gao, “Machine unlearning survey,” CSUR, p. 5, 2022, doi: 10.1117/12.2660330.*
* **T. Baumhauer**, *P. Schöttle, and M. Zeppelzauer, “Machine unlearning: linear filtration for logit-based classifiers,” Machine Learning, vol. 111, no. 9, pp. 3203–3226, 2022, doi: 10.1007/s10994-022-06178-9.*
* **N. Carlini**, *M. Jagielski, C. Zhang, N. Papernot, A. Terzis, and F. Tramer, “The Privacy Onion Effect: Memorization is Relative,” 2022.*
* **V. M. Suriyakumar and A. C. Wilson**, *“Algorithms that Approximate Data Removal: New Results and Limitations,” 2022.*
* **R. Tanno**, *M. F. Pradier, A. Nori, and Y. Li, “Repairing Neural Networks by Leaving the Right Past Behind,” in Advances in Neural Information Processing Systems, 2022, pp. 1–14.*
* **X. Lu et al.**, *“Quark: Controllable Text Generation with Reinforced Unlearning,” 2022.*
* **Z. Zhang**, *Y. Zhou, X. Zhao, T. Che, and L. Lyu, “Prompt Certified Machine Unlearning with Randomized Gradient Smoothing and Quantization,” in Advances in Neural Information Processing Systems, 2022, no. NeurIPS, pp. 1–23.*
* **G. Wu**, *M. Hashemi, and C. Srinivasa, “PUMA: Performance Unchanged Model Augmentation for Training Data Removal,” in Proceedings of the 36th AAAI Conference on Artificial Intelligence, AAAI 2022, 2022, vol. 36, pp. 8675–8682, doi: 10.1609/aaai.v36i8.20846.*
* **R. Mehta**, *S. Pal, V. Singh, and S. N. Ravi, “Deep Unlearning via Randomized Conditionally Independent Hessians,” in Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2022, vol. 2022-June, pp. 10412–10421, doi: 10.1109/CVPR52688.2022.01017.*
* **H. Yan**, *X. Li, Z. Guo, H. Li, F. Li, and X. Lin, “ARCANE: An Efficient Architecture for Exact Machine Unlearning,” in IJCAI International Joint Conference on Artificial Intelligence, 2022, pp. 4006–4013, doi: 10.24963/ijcai.2022/556.*
* **J. Wang**, *S. Guo, X. Xie, and H. Qi, “Federated Unlearning via Class-Discriminative Pruning,” in WWW 2022 - Proceedings of the ACM Web Conference 2022, 2022, pp. 622–632, doi: 10.1145/3485447.3512222.*
* **Y. Liu**, *L. Xu, X. Yuan, C. Wang, and B. Li, “The Right to be Forgotten in Federated Learning: An Efficient Realization with Rapid Retraining,” in Proceedings - IEEE INFOCOM, 2022, vol. 2022-May, pp. 1749–1758, doi: 10.1109/INFOCOM48880.2022.9796721.*
* **P.-F. Zhang**, *G. Bai, Z. Huang, and X.-S. Xu, “Machine Unlearning for Image Retrieval,” in Proceedings of the 30th ACM International Conference on Multimedia, Oct. 2022, pp. 237–245, doi: 10.1145/3503161.3548378.*
* **S. Shan**, *A. N. Bhagoji, H. Zheng, and B. Y. Zhao, “Poison Forensics: Traceback of Data Poisoning Attacks in Neural Networks,” in Proceedings of the 31st USENIX Security Symposium, Security 2022, 2022, pp. 3575–3592.*
* **N. G. Marchant**, *B. I. P. Rubinstein, and S. Alfeld, “Hard to Forget: Poisoning Attacks on Certified Machine Unlearning,” in Proceedings of the 36th AAAI Conference on Artificial Intelligence, AAAI 2022, 2022, vol. 36, pp. 7691–7700, doi: 10.1609/aaai.v36i7.20736.*
* **M. Chen**, *Z. Zhang, T. Wang, M. Backes, M. Humbert, and Y. Zhang, “Graph Unlearning,” in Proceedings of the ACM Conference on Computer and Communications Security, 2022, pp. 499–513, doi: 10.1145/3548606.3559352.*
* **Y. Liu et al.**, *“Backdoor Defense with Machine Unlearning,” in Proceedings - IEEE INFOCOM, 2022, vol. 2022-May, pp. 280–289, doi: 10.1109/INFOCOM48880.2022.9796974.*
* **C. Chen**, *F. Sun, M. Zhang, and B. Ding, “Recommendation Unlearning,” in WWW 2022 - Proceedings of the ACM Web Conference 2022, 2022, pp. 2768–2777, doi: 10.1145/3485447.3511997.*
* **T. T. Nguyen**, *T. T. Huynh, P. Le Nguyen, A. W.-C. Liew, H. Yin, and Q. V. H. Nguyen, “A Survey of Machine Unlearning,” 2022. http://arxiv.org/abs/2209.02299.*
* **A. Thudi**, *H. Jia, I. Shumailov, and N. Papernot, “On the Necessity of Auditable Algorithmic Definitions for Machine Unlearning,” in Proceedings of the 31st USENIX Security Symposium, Security 2022, 2022, pp. 4007–4022.*
* **J. Z. Di**, *J. Douglas, J. Acharya, G. Kamath, and A. Sekhari, “Hidden Poison: Machine Unlearning Enables Camouflaged Poisoning Attacks,” in 37th Conference on Neural Information Processing Systems (NeurIPS 2023), 2022, no. NeurIPS, pp. 1–27.*
* **H. Lin**, *J. W. Chung, Y. Lao, and W. Zhao, “Machine Unlearning in Gradient Boosting Decision Trees,” in Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Aug. 2023, pp. 1374–1383, doi: 10.1145/3580305.3599420.*
* **N. Su and B. Li**, *“Asynchronous Federated Unlearning,” Proc.~IEEE Conference on Computer Communications (INFOCOM), 2023.*
* **X. Zhu**, *G. Li, and W. Hu, Heterogeneous Federated Knowledge Graph Embedding Learning and Unlearning, vol. 1, no. 1. Association for Computing Machinery, 2023.*
* **C.-L. Wang**, *M. Huai, and D. Wang, “Inductive Graph Unlearning,” in USENIX Security, 2023, no. August.*
* **J. Cheng**, *G. Dasoulas, H. He, C. Agarwal, and M. Zitnik, “GNNDelete: A General Strategy for Unlearning in Graph Neural Networks,” in ICLR, 2023, pp. 1–24.*
* **M. Chen**, *W. Gao, G. Liu, K. Peng, and C. Wang, “Boundary Unlearning : Rapid Forgetting of Deep Networks via Shifting the Decision Boundary,” in CVPR, 2023, pp. 7766–7775.*
* **S. Lin**, *X. Zhang, C. Chen, X. Chen, and W. Susilo, “ERM-KTP : Knowledge-level Machine Unlearning via Knowledge Transfer,” 2023.*
* **Z. Wu**, *J. Zhu, Q. Li, and B. He, “DeltaBoost : Gradient Boosting Decision Trees with Efficient Machine Unlearning,” Proceedings of the ACM on Management of Data, vol. 1, no. 2, pp. 1–26, 2023, doi: 10.1145/3589313.*
* **J. Wu**, *Y. Yang, Y. Qian, Y. Sui, X. Wang, and X. He, “GIF: A General Graph Unlearning Strategy via Influence Function,” ACM Web Conference 2023 - Proceedings of the World Wide Web Conference, WWW 2023, pp. 651–661, 2023, doi: 10.1145/3543507.3583521.*
* **X. Cao**, *J. Jia, Z. Zhang, and N. Z. Gong, “FedRecover: Recovering from Poisoning Attacks in Federated Learning using Historical Information,” 2023, doi: 10.1109/SP46215.2023.00019.*
* **O. M. Chien Eli**, *Chao Pan, “Efficient Model Updates for Approximate Unlearning of Graph-Structured Data,” in The Eleventh International Conference on Learning Representations, 2023, pp. 1–10.*
* **A. Warnecke**, *L. Pirch, C. Wressnegger), and K. Rieck, “Machine Unlearning of Features and Labels,” in Proceedings 2023 Network and Distributed System Security Symposium, 2023, no. March, doi: 10.14722/ndss.2023.23087.*
* **Y. Dukler**, *B. Bowman, A. Achille, A. Golatkar, A. Swaminathan, and S. Soatto, “SAFE: Machine Unlearning With Shard Graphs,” in 2023 IEEE/CVF International Conference on Computer Vision (ICCV), Oct. 2023, pp. 17062–17072, doi: 10.1109/ICCV51070.2023.01569.*
* **J. Liu**, *M. Xue, J. Lou, X. Zhang, L. Xiong, and Z. Qin, “MUter: Machine Unlearning on Adversarially Trained Models,” in 2023 IEEE/CVF International Conference on Computer Vision (ICCV), Oct. 2023, pp. 4869–4879, doi: 10.1109/ICCV51070.2023.00451.*
* **J. Guo**, *A. Li, L. Wang, and C. Liu, “PolicyCleanse: Backdoor Detection and Mitigation for Competitive Reinforcement Learning,” in 2023 IEEE/CVF International Conference on Computer Vision (ICCV), Oct. 2023, pp. 4676–4685, doi: 10.1109/ICCV51070.2023.00433.*
* **S. Koh**, *H. Shon, J. Lee, H. G. Hong, and J. Kim, “Disposable Transfer Learning for Selective Source Task Unlearning,” in 2023 IEEE/CVF International Conference on Computer Vision (ICCV), Oct. 2023, no. Figure 1, pp. 11718–11726, doi: 10.1109/ICCV51070.2023.01079.*
* **R. Gandikota**, *J. Materzyńska, J. Fiotto-Kaufman, and D. Bau, “Erasing Concepts from Diffusion Models,” in 2023 IEEE/CVF International Conference on Computer Vision (ICCV), Oct. 2023, pp. 2426–2436, doi: 10.1109/ICCV51070.2023.00230.*
* **J. Xu**, *Z. Wu, C. Wang, and X. Jia, “Machine Unlearning: Solutions and Challenges,” IEEE Transactions on Emerging Topics in Computational Intelligence, vol. PP, pp. 1–19, 2023, doi: 10.1109/TETCI.2024.3379240.*
* **S. Wei**, *M. Zhang, H. Zha, and B. Wu, “Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples,” in 37th Conference on Neural Information Processing Systems (NeurIPS 2023), 2023, no. NeurIPS, pp. 1–34.*
* **J. Liu**, *J. Lou, Z. Qin, and K. Ren, “Certified Minimax Unlearning with Generalization Rates and Deletion Capacity,” in 37th Conference on Neural Information Processing Systems (NeurIPS 2023), 2023, no. NeurIPS, pp. 1–32.*
* **M. Kurmanji**, *P. Triantafillou, J. Hayes, and E. Triantafillou, “Towards Unbounded Machine Unlearning,” in 37th Conference on Neural Information Processing Systems (NeurIPS 2023), 2023, no. NeurIPS.*
* **R. Chen et al.**, *“Fast Model Debias with Machine Unlearning,” in 37th Conference on Neural Information Processing Systems (NeurIPS 2023), 2023, no. NeurIPS, pp. 1–24.*
* **J. Jia et al.**, *“Model Sparsity Can Simplify Machine Unlearning,” in 37th Conference on Neural Information Processing Systems (NeurIPS 2023), 2023, no. NeurIPS, pp. 1–22.*
* **Y. Li**, *D. Meng, and J. Wang, “UltraRE : Enhancing RecEraser for Recommendation Unlearning via Error Decomposition,” in 37th Conference on Neural Information Processing Systems (NeurIPS 2023), 2023, no. ML.*
* **A. Oesterling**, *J. Ma, F. P. Calmon, and H. Lakkaraju, “Fair Machine Unlearning: Data Removal while Mitigating Disparities,” in Proceedings of the 27th International Conference on Artificial Intelligence and Statistics (AISTATS) 2024, 2023, vol. 238.*
* **Y. Zhao**, *C. Li, and K. Chen, “UMA: Facilitating Backdoor Scanning via Unlearning-Based Model Ablation,” Proceedings of the AAAI Conference on Artificial Intelligence, vol. 38, no. 19, pp. 21823–21831, 2024, doi: 10.1609/aaai.v38i19.30183.*
* **Z. Liu**, *T. Wang, M. Huai, and C. Miao, “Backdoor Attacks via Machine Unlearning,” Proceedings of the AAAI Conference on Artificial Intelligence, vol. 38, no. 13, pp. 14115–14123, Mar. 2024, doi: 10.1609/aaai.v38i13.29321.*
* **X. Li**, *Y. Zhao, Z. Wu, W. Zhang, R. H. Li, and G. Wang, “Towards Effective and General Graph Unlearning via Mutual Evolution,” Proceedings of the AAAI Conference on Artificial Intelligence, vol. 38, no. 12, pp. 13682–13690, 2024, doi: 10.1609/aaai.v38i12.29273.*
* **M. Dreyer**, *F. Pahde, C. J. Anders, W. Samek, and S. Lapuschkin, “From Hope to Safety: Unlearning Biases of Deep Models via Gradient Penalization in Latent Space,” Proceedings of the AAAI Conference on Artificial Intelligence, vol. 38, no. 19, pp. 21046–21054, Mar. 2024, doi: 10.1609/aaai.v38i19.30096.*
* **H. Kim**, *S. Lee, and S. S. Woo, “Layer Attack Unlearning: Fast and Accurate Machine Unlearning via Layer Level Attack and Knowledge Distillation,” Proceedings of the AAAI Conference on Artificial Intelligence, vol. 38, no. 19, pp. 21241–21248, Mar. 2024, doi: 10.1609/aaai.v38i19.30118.*
* **X. You**, *J. Xu, M. Zhang, Z. Gao, and M. Yang, “RRL: Recommendation Reverse Learning,” Proceedings of the AAAI Conference on Artificial Intelligence, vol. 38, no. 8, pp. 9323–9331, 2024, doi: 10.1609/aaai.v38i8.28785.*
* **S. Moon**, *S. Cho, and D. Kim, “Feature Unlearning for Pre-trained GANs and VAEs,” Proceedings of the AAAI Conference on Artificial Intelligence, vol. 38, no. 19, pp. 21420–21428, 2024, doi: 10.1609/aaai.v38i19.30138.*
* **Y. Fraboni**, *L. Kameni, I. Paris, R. Vidal, M. Lorenzi, and I. Sophia-antipolis, “SIFU : Sequential Informed Federated Unlearning for E cient and Provable Client Unlearning in Federated Optimization,” in AISTATS 2024, 2024, vol. 238.*
* **C. Fu**, *W. Jia, and N. Ruan, “Client-Free Federated Unlearning via Training Reconstruction with Anchor Subspace Calibration,” in ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Apr. 2024, pp. 9281–9285, doi: 10.1109/ICASSP48485.2024.10447085.*
* **X. Gao et al.**, *“VeriFi: Towards Verifiable Federated Unlearning,” IEEE Transactions on Dependable and Secure Computing, pp. 1–16, 2024, doi: 10.1109/TDSC.2024.3382321.*
* **J. Foster**, *S. Schoepf, and A. Brintrup, “Fast Machine Unlearning without Retraining through Selective Synaptic Dampening,” Proceedings of the AAAI Conference on Artificial Intelligence, vol. 38, no. 11, pp. 12043–12051, Mar. 2024, doi: 10.1609/aaai.v38i11.29092.*
* **S. Cha**, *S. Cho, D. Hwang, H. Lee, T. Moon, and M. Lee, “Learning to Unlearn: Instance-Wise Unlearning for Pre-trained Classifiers,” Proceedings of the AAAI Conference on Artificial Intelligence, vol. 38, no. 10, pp. 11186–11194, Mar. 2024, doi: 10.1609/aaai.v38i10.28996.*
* **X. Hu**, *D. Li, B. Hu, Z. Zheng, Z. Liu, and M. Zhang, “Separate the Wheat from the Chaff: Model Deficiency Unlearning via Parameter-Efficient Module Operation,” Proceedings of the AAAI Conference on Artificial Intelligence, vol. 38, no. 16, pp. 18252–18260, Mar. 2024, doi: 10.1609/aaai.v38i16.29784.*
